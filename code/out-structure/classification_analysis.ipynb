{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-02T17:23:35.358381Z",
     "start_time": "2025-01-02T17:23:33.071471Z"
    }
   },
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from os import path\n",
    "\n",
    "#directory = \"results-gtm\"\n",
    "#directory = \"results-sgtm\"\n",
    "#directory = \"results-iter1\"\n",
    "#directory = \"results-sgtm-smote\"\n",
    "#directory = \"../out-content/results\"\n",
    "directory = \"results-iter2\"\n",
    "\n",
    "columns = [\"label\", \"prediction\", \"url\", \"visit_id\"]\n",
    "df = None\n",
    "\n",
    "\n",
    "# I ran 10-fold cross validation so there are 10 different files for test data predictions\n",
    "for i in range(10):\n",
    "    # The ML model output files use a weird separator: \" |$| \"\n",
    "    temp_df = pd.read_table(path.join(directory, f\"tp_{i}\"), header=None, sep=\"\\ \\|\\$\\|\\ \", names=columns, engine='python')\n",
    "\n",
    "    if df is None:\n",
    "        df = temp_df\n",
    "    else:\n",
    "        df = pd.concat([df, temp_df])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siim/WebGraph/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## False Positives analysis\n",
    "We want to check whether our model can find other server-side tracker requests (in addition to GTM)"
   ],
   "id": "317cce3773078afb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T17:23:51.282715Z",
     "start_time": "2025-01-02T17:23:51.253894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# False Negatives\n",
    "fn = df[df[\"prediction\"] & ~df[\"label\"]]\n",
    "\n",
    "# False negatives where url contains \"/j/collect\" (that seems to be an alternative of \"/g/collect\")\n",
    "#fn = df[df[\"prediction\"] & ~df[\"label\"] & df[\"url\"].str.contains(\"/j/collect\") ]\n",
    "\n",
    "fn.to_csv(\"temp_df.csv\")\n",
    "fn"
   ],
   "id": "af0306a2cc6fea69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       label  prediction                                                url  \\\n",
       "1102   False        True  https://ml314.com/utsync.ashx?pub=&adv=&et=0&e...   \n",
       "1107   False        True  https://www.google.ee/ads/ga-audiences?v=1&t=s...   \n",
       "1111   False        True  https://www.google.ee/ads/ga-audiences?v=1&t=s...   \n",
       "1112   False        True  https://googleads.g.doubleclick.net/pagead/vie...   \n",
       "1113   False        True  https://googleads.g.doubleclick.net/pagead/vie...   \n",
       "...      ...         ...                                                ...   \n",
       "67583  False        True  https://ingest.quantummetric.com/horizon/lumen...   \n",
       "67584  False        True  https://ingest.quantummetric.com/horizon/lumen...   \n",
       "67858  False        True  https://sb.scorecardresearch.com/b?c1=2&c2=690...   \n",
       "67859  False        True  https://sb.scorecardresearch.com/b?c1=2&c2=690...   \n",
       "68153  False        True  https://s4i.histats.com/stats/i/4600141.gif?46...   \n",
       "\n",
       "               visit_id  \n",
       "1102     65860553664439  \n",
       "1107     65860553664439  \n",
       "1111     65860553664439  \n",
       "1112     65860553664439  \n",
       "1113     65860553664439  \n",
       "...                 ...  \n",
       "67583  8792294440948776  \n",
       "67584  8792294440948776  \n",
       "67858  8889417237623677  \n",
       "67859  8889417237623677  \n",
       "68153  8945335089380096  \n",
       "\n",
       "[2054 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>url</th>\n",
       "      <th>visit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://ml314.com/utsync.ashx?pub=&amp;adv=&amp;et=0&amp;e...</td>\n",
       "      <td>65860553664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.google.ee/ads/ga-audiences?v=1&amp;t=s...</td>\n",
       "      <td>65860553664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://www.google.ee/ads/ga-audiences?v=1&amp;t=s...</td>\n",
       "      <td>65860553664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://googleads.g.doubleclick.net/pagead/vie...</td>\n",
       "      <td>65860553664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://googleads.g.doubleclick.net/pagead/vie...</td>\n",
       "      <td>65860553664439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67583</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://ingest.quantummetric.com/horizon/lumen...</td>\n",
       "      <td>8792294440948776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67584</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://ingest.quantummetric.com/horizon/lumen...</td>\n",
       "      <td>8792294440948776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67858</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://sb.scorecardresearch.com/b?c1=2&amp;c2=690...</td>\n",
       "      <td>8889417237623677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67859</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://sb.scorecardresearch.com/b?c1=2&amp;c2=690...</td>\n",
       "      <td>8889417237623677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68153</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>https://s4i.histats.com/stats/i/4600141.gif?46...</td>\n",
       "      <td>8945335089380096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2054 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## All Server-side GTM predictions",
   "id": "aa06d51f89417514"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:45:54.901360Z",
     "start_time": "2025-01-02T13:45:53.771230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_google(df):\n",
    "    google_domains = ['region1.google-analytics.com', 'region1.analytics.google.com', 'stats.g.doubleclick.net', 'www.google-analytics.com', 'analytics.google.com']\n",
    "    values = df[\"url\"].str.contains(\"|\".join(google_domains), regex=True)\n",
    "    return values\n",
    "\n",
    "df_sgtm = df[df[\"url\"].str.contains('/g/collect') & ~ is_google(df)]\n",
    "#df_sgtm.to_csv(\"temp_df.csv\")"
   ],
   "id": "c02c3dd4212a4019",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T13:45:54.911346Z",
     "start_time": "2025-01-02T13:45:54.905658Z"
    }
   },
   "cell_type": "code",
   "source": "df_sgtm[\"prediction\"].value_counts()\n",
   "id": "31c93963a71c9252",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    161\n",
       "True       3\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aggregated statistics\n",
    "The WebGraph ML model outputs"
   ],
   "id": "85ffb09f50c6625f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-02T18:04:01.462213Z",
     "start_time": "2025-01-02T18:03:48.863617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import os\n",
    "\n",
    "\n",
    "def report_to_latex(report, table_name):\n",
    "    \"\"\" Parse sklearn.metrics.classification_report into a latex table.\n",
    "\n",
    "    Code adapted from: https://gist.github.com/Lorenzoantonelli/40454798ae53386a1d5b9c8bb60664d5\n",
    "    \"\"\"\n",
    "\n",
    "    if report[0] == '\\n':\n",
    "        report = report[1:]\n",
    "    if report[-1] == '\\n':\n",
    "        report = report[:-1]\n",
    "\n",
    "    lines = report.split('\\n')\n",
    "\n",
    "    header = [\"\\\\begin{table}\",\n",
    "              f\"\\\\caption{{Classification Report for {table_name}}}\",\n",
    "              f\"\\\\label{{table:classification:{table_name}}}\",\n",
    "              \"\\\\centering\",\n",
    "              \"\\\\begin{tabular}{r r r r r}\",\n",
    "              \"& Precision & Recall & F-score & Support\",\n",
    "              \"\\\\\\\\\"]\n",
    "\n",
    "    body = []\n",
    "    for line in lines[2:-4]:\n",
    "        row = line.split()\n",
    "        if len(row) == 5:\n",
    "            body.append(\" & \".join(row) + \"\\\\\\\\\")\n",
    "\n",
    "    body.append(\"\\\\\\\\\")\n",
    "\n",
    "    footer = []\n",
    "    for line in lines[-3:]:\n",
    "        row = line.split()\n",
    "        if len(row) == 3:\n",
    "            footer.append(\"{} & & & {} & {}\\\\\\\\\".format(*row))\n",
    "        elif len(row) == 6:\n",
    "            footer.append(\"{} {} & {} & {} & {} & {}\\\\\\\\\".format(*row))\n",
    "\n",
    "    footer.extend([\"\\\\end{tabular}\", \"\\\\end{table}\"])\n",
    "\n",
    "    latex_table = '\\n'.join(header + body + footer)\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "result_dirs  = [ f.name for f in os.scandir(\".\") if f.is_dir() and f.name.startswith(\"results-\") ]\n",
    "\n",
    "df_dict = {}\n",
    "for dirname in result_dirs:\n",
    "    # Skip unfinished ML jobs\n",
    "    if not os.path.isfile(os.path.join(dirname, \"tp_9\")):\n",
    "        continue\n",
    "\n",
    "    columns = [\"label\", \"prediction\", \"url\", \"visit_id\"]\n",
    "    #df = pd.DataFrame(columns=columns)\n",
    "    df = None\n",
    "\n",
    "    # I ran 10-fold cross validation so there are 10 different files for test data predictions\n",
    "    for i in range(10):\n",
    "        # The ML model output files use a weird separator: \" |$| \"\n",
    "        temp_df = pd.read_table(path.join(dirname, f\"tp_{i}\"), header=None, sep=\"\\ \\|\\$\\|\\ \", names=columns, engine='python', usecols=[\"label\", \"prediction\"])\n",
    "        if df is None:\n",
    "            df = temp_df\n",
    "        else:\n",
    "            df = pd.concat([df, temp_df])\n",
    "\n",
    "    #df_dict[dirname] = df.copy()\n",
    "\n",
    "\n",
    "    print(\"#######################################################################################################################################\")\n",
    "    print(dirname)\n",
    "    results = classification_report(y_true=df[\"label\"].to_numpy(), y_pred=df[\"prediction\"].to_numpy())\n",
    "    #print(report_to_latex(results, dirname))\n",
    "    print(results)"
   ],
   "id": "44b1e08b2dc3a62e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################################################################################################\n",
      "results-sgtm-smote\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00    678328\n",
      "        True       0.52      0.16      0.24       164\n",
      "\n",
      "    accuracy                           1.00    678492\n",
      "   macro avg       0.76      0.58      0.62    678492\n",
      "weighted avg       1.00      1.00      1.00    678492\n",
      "\n",
      "#######################################################################################################################################\n",
      "results-gtm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00    765544\n",
      "        True       0.59      0.32      0.42      6478\n",
      "\n",
      "    accuracy                           0.99    772022\n",
      "   macro avg       0.79      0.66      0.71    772022\n",
      "weighted avg       0.99      0.99      0.99    772022\n",
      "\n",
      "#######################################################################################################################################\n",
      "results-sgtm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00    678163\n",
      "        True       1.00      0.02      0.05       164\n",
      "\n",
      "    accuracy                           1.00    678327\n",
      "   macro avg       1.00      0.51      0.52    678327\n",
      "weighted avg       1.00      1.00      1.00    678327\n",
      "\n",
      "#######################################################################################################################################\n",
      "results-iter2-smote\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.99      0.99    670100\n",
      "        True       0.44      0.61      0.51      8305\n",
      "\n",
      "    accuracy                           0.99    678405\n",
      "   macro avg       0.72      0.80      0.75    678405\n",
      "weighted avg       0.99      0.99      0.99    678405\n",
      "\n",
      "#######################################################################################################################################\n",
      "results-iter1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00    671491\n",
      "        True       0.67      0.49      0.57      7070\n",
      "\n",
      "    accuracy                           0.99    678561\n",
      "   macro avg       0.83      0.74      0.78    678561\n",
      "weighted avg       0.99      0.99      0.99    678561\n",
      "\n",
      "#######################################################################################################################################\n",
      "results-iter2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00    670057\n",
      "        True       0.68      0.52      0.59      8308\n",
      "\n",
      "    accuracy                           0.99    678365\n",
      "   macro avg       0.84      0.76      0.79    678365\n",
      "weighted avg       0.99      0.99      0.99    678365\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
